{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a6908c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "class PolicyIteration:\n",
    "  def __init__(self, states, actions, reward_func=None):\n",
    "    self.states = states\n",
    "    self.actions = actions\n",
    "    self.reward_func = lambda x: x == 1 and 1 or -1 # sample function\n",
    "    self.values = dict(zip(self.states, [0] * len(self.states))) # all zeroes\n",
    "    self.transitional_model = dict(zip(self.states, \n",
    "                                       [dict(zip(self.actions, [random.random() for a in self.actions])) for s in self.states])) # random transitions\n",
    "    self.discount = 0.9 # usually denoted as gamma\n",
    "    self.convergence_threshold = 0.1 # usually denoted as theta\n",
    "    self.policy = dict(zip(self.states, random.choices(self.actions, k=4))) # random actions\n",
    "    \n",
    "  def evaluate_policy(self):\n",
    "    delta = 0\n",
    "    for state in self.states:\n",
    "      action = self.policy[state]\n",
    "      prob = self.transitional_model[state][action]\n",
    "      value = self.values[state]\n",
    "      all_values = sum(self.values)\n",
    "      new_value = self.reward_func(state) + self.discount * prob * all_values\n",
    "      self.values[state] = new_value\n",
    "      delta = max(delta, abs(value - new_value))\n",
    "    return delta\n",
    "  \n",
    "  def improve_policy(self):\n",
    "    policy_changed = False\n",
    "    for state in self.states:\n",
    "      old_action = self.policy[state]\n",
    "      action_value = [0] * len(self.actions)\n",
    "      for action in self.actions:\n",
    "        prob = self.transitional_model[state][action]\n",
    "        all_values = sum(self.values)\n",
    "        action_value[action] = prob * all_values\n",
    "      new_action = action_value.index(max(action_value))\n",
    "      self.policy[state] = new_action\n",
    "      policy_changed = policy_changed or (new_action != old_action)\n",
    "    return policy_changed\n",
    "  \n",
    "  def train(self, max_epoch=500):\n",
    "    epoch = 0\n",
    "    while epoch < max_epoch:\n",
    "      epoch += 1\n",
    "      self.evaluate_policy()\n",
    "      changed = self.improve_policy()\n",
    "      if not changed:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c6380bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = PolicyIteration(states=[1,2,3,4], actions=[1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3356e44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solver.states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7979fa1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solver.actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "393c6eef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 0, 2: 0, 3: 0, 4: 0}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solver.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd5f9900",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8715986035960382"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solver.transitional_model[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "230787ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 1, 2: 2, 3: 1, 4: 1}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solver.policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ad488bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "solver.transitional_model = dict(zip(solver.states, [dict(zip(solver.actions, [random.random() for a in solver.actions])) for s in solver.states]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "22ce71d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.155220681388876"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solver.evaluate_policy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "12b35f91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 8.844387432364345,\n",
       " 2: 3.292557663026728,\n",
       " 3: 3.263194900964023,\n",
       " 4: 4.10457255598351}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solver.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "35d292c1",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list assignment index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m-------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                        Traceback (most recent call last)",
      "Input \u001b[1;32mIn [18]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43msolver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimprove_policy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36mPolicyIteration.improve_policy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     34\u001b[0m   prob \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransitional_model[state][action]\n\u001b[0;32m     35\u001b[0m   all_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues)\n\u001b[1;32m---> 36\u001b[0m   action_value[action] \u001b[38;5;241m=\u001b[39m prob \u001b[38;5;241m*\u001b[39m all_values\n\u001b[0;32m     37\u001b[0m new_action \u001b[38;5;241m=\u001b[39m action_value\u001b[38;5;241m.\u001b[39mindex(\u001b[38;5;28mmax\u001b[39m(action_value))\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy[state] \u001b[38;5;241m=\u001b[39m new_action\n",
      "\u001b[1;31mIndexError\u001b[0m: list assignment index out of range"
     ]
    }
   ],
   "source": [
    "solver.improve_policy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d7cd63a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1 0.8715986035960382\n",
      "1 2 0.14836439865606244\n",
      "2 1 0.7438542360077686\n",
      "2 2 0.4769508514474142\n",
      "3 1 0.4736883223293359\n",
      "3 2 0.36134471794816714\n",
      "4 1 0.5671747284426122\n",
      "4 2 0.2892776979191115\n"
     ]
    }
   ],
   "source": [
    "for state in solver.states:\n",
    "    for action in solver.actions:\n",
    "        print(state, action, solver.transitional_model[state][action])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6cb9a402",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 1, 2: 2, 3: 1, 4: 1}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solver.policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4bf9cc70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def improve_policy_new(self):\n",
    "    policy_changed = False\n",
    "    for state in self.states:\n",
    "      old_action = self.policy[state]\n",
    "      action_value = dict(zip(self.actions, [0] * len(self.actions)))\n",
    "      for action in self.actions:\n",
    "        prob = self.transitional_model[state][action]\n",
    "        all_values = sum(self.values)\n",
    "        action_value[action] = prob * all_values\n",
    "      new_action = max(action_value, key=action_value.get)\n",
    "      self.policy[state] = new_action\n",
    "      policy_changed = policy_changed or (new_action != old_action)\n",
    "    return policy_changed\n",
    "\n",
    "PolicyIteration.improve_policy = improve_policy_new\n",
    "solver.improve_policy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ebc79caf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 1, 2: 1, 3: 2, 4: 2}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solver.policy = dict(zip(solver.states, random.choices(solver.actions, k=4)))\n",
    "solver.policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c2e148",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
