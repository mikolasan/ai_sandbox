{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self organizing maps"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is SOM but not SOM"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sub-area connections\n",
    "\n",
    "We will start with a network that has 3 layers. The first layer is sensors. And the network will have a difference with standard artificial neural networks. \n",
    "\n",
    "The difference is that every neuron $i$ in the presynaptic layer has a matrix $W_i$ instead of having only one matrix $W$ for the whole layer. These matrices, $W_i$ connect the neuron $i$ with a subset of neurons in the next layer. This subset is a group of neurons located just above the neuron $i$ within a radius $r$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.0 0\n",
      "1 0.3333333333333333 0\n",
      "2 0.6666666666666666 0\n",
      "3 1.0 1\n",
      "4 1.3333333333333333 1\n",
      "5 1.6666666666666665 1\n",
      "6 2.0 2\n",
      "7 2.333333333333333 2\n",
      "8 2.6666666666666665 2\n",
      "9 3.0 3\n",
      "10 3.333333333333333 3\n",
      "11 3.6666666666666665 3\n",
      "12 4.0 4\n",
      "13 4.333333333333333 4\n",
      "14 4.666666666666666 4\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "input_x = 15\n",
    "output_x = 9\n",
    "radius = 4\n",
    "for i in range(input_x):\n",
    "    k = ((output_x - radius) / input_x) * i\n",
    "    print(i, k, math.floor(k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColumnLayer:\n",
    "    def __init__(self, input_shape, output_shape, radius, init_std=0.01):\n",
    "        \"\"\"\n",
    "        Initialize the network.\n",
    "        \n",
    "        Args:\n",
    "            input_shape (tuple): Shape of the input layer (height, width).\n",
    "            output_shape (tuple): Shape of the output layer (height, width).\n",
    "            radius (int): Radius for the connection neighborhood.\n",
    "            init_std (float): Standard deviation for weight initialization.\n",
    "        \"\"\"\n",
    "        self.input_shape = input_shape\n",
    "        self.output_shape = output_shape\n",
    "        self.radius = radius\n",
    "        \n",
    "        # Initialize weights for each neuron in the input grid\n",
    "        self.weights = []\n",
    "        for i in range(input_shape[0]):\n",
    "            row_weights = []\n",
    "            for j in range(input_shape[1]):\n",
    "                w_shape = (self.radius, self.radius)\n",
    "                row_weights.append(torch.randn(w_shape) * init_std)\n",
    "            self.weights.append(row_weights)\n",
    "\n",
    "    def area_position(self, x, y):\n",
    "        row_start = math.floor(((self.output_shape[0] - self.radius) / self.input_shape[0]) * x)\n",
    "        row_end = row_start + self.radius\n",
    "        col_start = math.floor(((self.output_shape[1] - self.radius) / self.input_shape[1]) * y)\n",
    "        col_end = col_start + self.radius\n",
    "        \n",
    "        return (slice(row_start, row_end), slice(col_start, col_end))\n",
    "    \n",
    "    def forward(self, input_grid):\n",
    "        \"\"\"\n",
    "        Perform a forward pass of the network.\n",
    "        \n",
    "        Args:\n",
    "            input_grid (torch.Tensor): Input tensor of shape (H_in, W_in).\n",
    "        \n",
    "        Returns:\n",
    "            torch.Tensor: Output tensor of shape (H_out, W_out).\n",
    "        \"\"\"\n",
    "        output_grid = torch.zeros(self.output_shape)\n",
    "        \n",
    "        for i in range(self.input_shape[0]):\n",
    "            for j in range(self.input_shape[1]):\n",
    "                weight = self.weights[i][j]\n",
    "                (x_s, y_s) = self.area_position(i, j)\n",
    "                output_slice = output_grid[x_s, y_s]\n",
    "                \n",
    "                # Update the output slice based on the weight and input\n",
    "                output_slice += input_grid[i, j] * weight\n",
    "                \n",
    "        return output_grid\n",
    "\n",
    "    def update_weights(self, x, y_t, learning_rate=0.05):\n",
    "        \"\"\"\n",
    "        Manually update weights based on provided gradients.\n",
    "        \n",
    "        Args:\n",
    "            gradients (list of lists of torch.Tensor): Gradient for each weight matrix.\n",
    "            learning_rate (float): Learning rate for weight updates.\n",
    "        \"\"\"\n",
    "        for i in range(self.input_shape[0]):\n",
    "            for j in range(self.input_shape[1]):\n",
    "                \n",
    "                w = self.weights[i][j]\n",
    "                (x_s, y_s) = self.area_position(i, j)\n",
    "                oja = y_t * (x - y_t * w)\n",
    "                self.weights[i][j] += learning_rate * oja\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have inputs to an Artificial Neural Network like these:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.tensor([\n",
    "  [0, 0, 0, 0, 0],\n",
    "  [0, 0, 0, 0, 0],\n",
    "  [0, 0, 0, 0, 0],\n",
    "  [0, 0, 0, 0, 0],\n",
    "  [1, 1, 1, 1, 1]\n",
    "], dtype=torch.float)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They represent some geometric objects. In this case it's a line.\n",
    "\n",
    "The receptive field in our ANN will be bigger than this input. Every input is randomly moved.\n",
    "\n",
    "So next, we take the input and create K=5 displacements (moving the original tensor in receptive field by (x,y) offset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 5\n",
    "N = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_displaced_tensors(tensor, K, receptive_field_size=(15, 15)):\n",
    "    \"\"\"\n",
    "    Creates K displacements of the input tensor by moving it within a larger receptive field.\n",
    "    \n",
    "    Parameters:\n",
    "        tensor (torch.Tensor): The original input tensor of shape (5, 5).\n",
    "        K (int): The number of displacements to create.\n",
    "        receptive_field_size (tuple): The dimensions of the receptive field (height, width).\n",
    "        \n",
    "    Returns:\n",
    "        batch of tensors: A tensor of K tensors with the original tensor displaced within the receptive field.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create a larger tensor filled with zeros (the receptive field)\n",
    "    receptive_field_h, receptive_field_w = receptive_field_size\n",
    "    displaced_tensors = torch.zeros(K, receptive_field_h, receptive_field_w, dtype=tensor.dtype)\n",
    "    \n",
    "    # Calculate padding size based on the receptive field dimensions\n",
    "    input_h, input_w = tensor.shape\n",
    "    padding_h = receptive_field_h - input_h\n",
    "    padding_w = receptive_field_w - input_w\n",
    "    \n",
    "    for i in range(K):\n",
    "        # Randomly choose top-left corner for placing the input tensor within the receptive field\n",
    "        max_x_offset = padding_h\n",
    "        max_y_offset = padding_w\n",
    "        x_offset = random.randint(0, max_x_offset)\n",
    "        y_offset = random.randint(0, max_y_offset)\n",
    "        \n",
    "        # Place the input tensor within the receptive field at the chosen offset\n",
    "        displaced_tensors[i, x_offset:x_offset + input_h, y_offset:y_offset + input_w] = tensor\n",
    "\n",
    "    return displaced_tensors\n",
    "\n",
    "input_saccades = create_displaced_tensors(input,\n",
    "                                          K=K,\n",
    "                                          receptive_field_size=(N, N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1, K, figsize=(12, 4))\n",
    "for i in range(K):\n",
    "    axs[i].imshow(input_saccades[i].detach().numpy(), cmap=cm.Purples)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_input = torch.tensor([\n",
    "  [1, 1, 1, 1, 1],\n",
    "  [1, 0, 0, 0, 1],\n",
    "  [1, 0, 0, 0, 1],\n",
    "  [1, 0, 0, 0, 1],\n",
    "  [1, 1, 1, 1, 1]\n",
    "], dtype=torch.float)\n",
    "test_set = create_displaced_tensors(new_input,\n",
    "                                    K=K,\n",
    "                                    receptive_field_size=(N, N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (N, N)\n",
    "output_shape = (8, 8)\n",
    "radius = 4\n",
    "\n",
    "layer = ColumnLayer(input_shape, output_shape, radius, init_std=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1, K, figsize=(12, 4))\n",
    "for i in range(K):\n",
    "    x = input_saccades[i] # what is activated from sensors\n",
    "    y = layer.forward(x)\n",
    "    # y_t = y.unsqueeze(0).T\n",
    "    # layer.update_weights(x, y_t)\n",
    "    axs[i].imshow(y.detach().numpy(), cmap=cm.Purples)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Columns\n",
    "\n",
    "In order to prepare the network to have connections in more sparse but also tangled way, we need more intricate structures that represent these connections.\n",
    "\n",
    "First of all, there is no need to connect a neuron from one corner to absolutely opposite area on the next layer. Neurons are generally organized in columns. So higher amount of connected layers prevails over simultaneous connections to all the neurons on the next level. Which means that instead of a big matrix $W$ that covers the whole layer, we will be using smaller matrices $W_r$ that work only within a radius $r$. Although that radius covers several layers above the neuron.\n",
    "\n",
    "And there are two approaches here. One is when the matrix is assigned to the initiating neuron. It is absolutely straight forward for the forward pass because it follows the activation potential.\n",
    "\n",
    "One the other side, it mixes synapses from different neurons and doesn't represent the full picture of the full dendrite network of one neuron. So this is the opposite matrix that has all synapses for all dendrites.\n",
    "\n",
    "When you know all activations from sensors then in the first case matrices will define what next neurons are activated. In the second case, matrices from all neurons should be applied because sensors don't have information about post synaptic connections.\n",
    "\n",
    "The diff for the learning update is simpler for the second case because it applies to every matrix separately. While in the first case the update is a sum of several matrices (the number is not known). But the update must happen along the activation path and doesn't need to affect the whole neuron. Which means the first method is preferable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neuron:\n",
    "    def __init__(self, pos, column_height, column_width, n_dendrites, n_synapses):\n",
    "        self.pos = pos\n",
    "        self.column_height = column_height\n",
    "        self.column_width = column_width\n",
    "        self.n_dendrites = n_dendrites\n",
    "        self.n_synapses = n_synapses\n",
    "        \n",
    "        n_post_neurons = column_height * column_width\n",
    "        # n = n_post_neurons * n_dendrites * n_synapses\n",
    "        \n",
    "        self.weight = torch.randn((1, n_post_neurons))\n",
    "        \n",
    "        self.learning_rate = 0.05\n",
    "\n",
    "    def i_to_neuron_pos(self, i):\n",
    "        if self.column_width % 2 == 0:\n",
    "            # no neuron on the same position above the current one\n",
    "            start_pos = - (self.column_width // 2) + 1\n",
    "        else:\n",
    "            start_pos = - (self.column_width // 2)\n",
    "        level = i // (self.column_width * self.column_width)\n",
    "        level_i = i % (self.column_width * self.column_width)\n",
    "        return (start_pos + self.pos[0] + level_i % self.column_width,\n",
    "                start_pos + self.pos[1] + level_i // self.column_width,\n",
    "                level)\n",
    "        # if level < 1:\n",
    "        #     # first level\n",
    "        #     return (start_pos + self.pos[0] + i % self.column_width,\n",
    "        #             start_pos + self.pos[1] + i // self.column_width,\n",
    "        #             0)\n",
    "        # else:\n",
    "        #     # not the first level\n",
    "        #     # print(i, level, \"not the first level\")\n",
    "        #     level_i = i % (self.column_width * self.column_width)\n",
    "        #     return (start_pos + self.pos[0] + level_i % self.column_width,\n",
    "        #             start_pos + self.pos[1] + level_i // self.column_width,\n",
    "        #             level)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x is a scalar.\n",
    "        It basically indicates if this column is activated or not.\n",
    "        and if it is then it works as a multiplier \n",
    "        (maybe important during summation and threshold within an activation function)\n",
    "        \n",
    "        The output is an array of neurons across this column\n",
    "        \"\"\"\n",
    "        return x * self.weight\n",
    "\n",
    "    def update_weights(self, x, y):\n",
    "        oja_diff = y * (x - y * self.weight)\n",
    "        self.weights += self.learning_rate * oja_diff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_width = 15\n",
    "field_height = 15\n",
    "\n",
    "column_height = 3\n",
    "column_width = 2\n",
    "\n",
    "n_dendrites = 12 # some of them are in the column width but some can lie outside\n",
    "n_synapses = 4 # possible duplicate connections between pre-synaptic axon and post-synaptic dendrites\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron = Neuron(\n",
    "    (1, 4),\n",
    "    column_height=column_height,\n",
    "    column_width=column_width,\n",
    "    n_dendrites=n_dendrites,\n",
    "    n_synapses=n_synapses\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (1, 4, 0)\n",
      "1 (2, 4, 0)\n",
      "2 (1, 5, 0)\n",
      "3 (2, 5, 0)\n",
      "4 (1, 4, 1)\n",
      "5 (2, 4, 1)\n",
      "6 (1, 5, 1)\n",
      "7 (2, 5, 1)\n",
      "8 (1, 4, 2)\n",
      "9 (2, 4, 2)\n",
      "10 (1, 5, 2)\n",
      "11 (2, 5, 2)\n"
     ]
    }
   ],
   "source": [
    "for i in range(column_width * column_width * column_height):\n",
    "    pos = neuron.i_to_neuron_pos(i)\n",
    "    print(i, pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "neurons = []\n",
    "\n",
    "for x in range(field_width):\n",
    "    for y in range(field_height):\n",
    "        neuron = Neuron(\n",
    "            (x, y),\n",
    "            column_height=column_height,\n",
    "            column_width=column_width,\n",
    "            n_dendrites=n_dendrites,\n",
    "            n_synapses=n_synapses\n",
    "        )\n",
    "        neurons.append(neuron)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = input_saccades[0]\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.8247, -2.2826,  4.7866, -4.7525, -1.9769,  1.1854]])"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yy = []\n",
    "for x in range(field_width):\n",
    "    row = []\n",
    "    for y in range(field_height):\n",
    "        row.append(torch.zeros(5))\n",
    "    yy.append(row)\n",
    "\n",
    "y_total = torch.zeros_like(neurons[0].weight)\n",
    "\n",
    "for n in neurons:\n",
    "    xx = input_saccades[0][n.pos[0], n.pos[1]]\n",
    "    y = n.forward(xx)\n",
    "    yy[n.pos[0]][n.pos[1]] = y\n",
    "    y_total += y\n",
    "\n",
    "# yy\n",
    "y_total\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6])"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_total.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real SOM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SOM(nn.Module):\n",
    "    \"\"\"\n",
    "    2-D Self-Organizing Map with Gaussian Neighbourhood function\n",
    "    and linearly decreasing learning rate.\n",
    "    \"\"\"\n",
    "    def __init__(self, m, n, dim, alpha=None, sigma=None):\n",
    "        super(SOM, self).__init__()\n",
    "        self.m = m\n",
    "        self.n = n\n",
    "        self.dim = dim\n",
    "        self.n_neurons = self.m * self.n\n",
    "        # gain coefficient\n",
    "        self.alpha = 0.3\n",
    "        # correction\n",
    "        self.sigma = max(m, n) / 2.0\n",
    "        \n",
    "        if alpha is not None:\n",
    "            self.alpha = float(alpha)\n",
    "        if sigma is not None:\n",
    "            self.sigma = float(sigma)\n",
    "\n",
    "        self.weights = torch.randn(self.n_neurons, dim)\n",
    "        self.locations = torch.tensor(np.array(list(self.make_grid_locations_iter(m, n))), dtype=torch.int32)\n",
    "        self.pdist = nn.PairwiseDistance(p=2)\n",
    "\n",
    "    def get_weights(self):\n",
    "        return self.weights\n",
    "\n",
    "    def get_locations(self):\n",
    "        return self.locations\n",
    "\n",
    "    def make_grid_locations_iter(self, m, n):\n",
    "        for i in range(m):\n",
    "            for j in range(n):\n",
    "                yield np.array([i, j])\n",
    "\n",
    "    def map_vects(self, input_vects):\n",
    "        to_return = []\n",
    "        for vect in input_vects:\n",
    "            min_index = min([i for i in range(self.n_neurons)],\n",
    "                            key=lambda x: np.linalg.norm(vect-self.weights[x]))\n",
    "            to_return.append(self.locations[min_index])\n",
    "\n",
    "        return to_return\n",
    "\n",
    "    def forward(self, x, learning_rate_op):\n",
    "        dists = self.pdist(x, self.weights) # compare X with every column in W. columns is a batch dimension\n",
    "        bmu_index = dists.min(0).indices # find the minimum distance\n",
    "        bmu_loc = self.locations[bmu_index,:]\n",
    "        \n",
    "        alpha_op = self.alpha * learning_rate_op\n",
    "        sigma_op = self.sigma * learning_rate_op\n",
    "\n",
    "        diff = self.locations - bmu_loc # .unsqueeze(0).repeat(self.n_neurons, 1) - don't need to copy because broadcasting will do it (ref: https://numpy.org/doc/stable/user/basics.broadcasting.html)\n",
    "        bmu_distance_squares = torch.sum(torch.pow(diff.float(), 2), 1) # array where for every neuron i: x_i ^2 + y_i ^2 -> d_i\n",
    "        neighbourhood_func = torch.exp(torch.neg(torch.div(bmu_distance_squares, sigma_op**2))) # e^{ -(d_i / sigma^2) }\n",
    "        gain_coefficient = alpha_op * neighbourhood_func\n",
    "        learning_rate_multiplier = gain_coefficient.repeat(self.dim, 1).T # copy to every dimension\n",
    "        delta = torch.mul(learning_rate_multiplier, x - self.weights) # (x - self.weights) - uses broadcasting too\n",
    "\n",
    "        self.weights += delta\n",
    "    \n",
    "    def forward_no_training(self, x):\n",
    "        # find a location where the distance between x and m_i is the minimum \n",
    "        min_index = torch.linalg.vector_norm(x - self.weights, ord=2, dim=1).min(0).indices\n",
    "        return self.locations[min_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[210], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m n_iter \u001b[39m=\u001b[39m \u001b[39m5\u001b[39m\n\u001b[0;32m      3\u001b[0m som_dim \u001b[39m=\u001b[39m N \u001b[39m*\u001b[39m N\n\u001b[1;32m----> 4\u001b[0m som \u001b[39m=\u001b[39m SOM(N, N, som_dim)\n\u001b[0;32m      6\u001b[0m \u001b[39mfor\u001b[39;00m iter_no \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_iter):\n\u001b[0;32m      7\u001b[0m     data \u001b[39m=\u001b[39m create_displaced_tensors(\u001b[39minput\u001b[39m, K\u001b[39m=\u001b[39mbatch_size, receptive_field_size\u001b[39m=\u001b[39m(N, N))\n",
      "Cell \u001b[1;32mIn[209], line 23\u001b[0m, in \u001b[0;36mSOM.__init__\u001b[1;34m(self, m, n, dim, alpha, sigma)\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msigma \u001b[39m=\u001b[39m \u001b[39mfloat\u001b[39m(sigma)\n\u001b[0;32m     22\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweights \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrandn(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_neurons, dim)\n\u001b[1;32m---> 23\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlocations \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(np\u001b[39m.\u001b[39marray(\u001b[39mlist\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmake_grid_locations_iter(m, n))), dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mint32)\n\u001b[0;32m     24\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpdist \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mPairwiseDistance(p\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "n_iter = 5\n",
    "som_dim = N * N\n",
    "som = SOM(N, N, som_dim)\n",
    "\n",
    "for iter_no in range(n_iter):\n",
    "    data = create_displaced_tensors(input, K=batch_size, receptive_field_size=(N, N))\n",
    "    # data dimension is 225 (15x15)\n",
    "    for i in range(len(data)):\n",
    "        learning_rate_op = 1.0 - iter_no/(1.0*n_iter)\n",
    "        som(data[i], learning_rate_op)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffusers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
