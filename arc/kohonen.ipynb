{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kohonen\n",
    "\n",
    "[Some code](https://github.com/giannisnik/som/blob/master/som.py) for SOM in Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    " \n",
    "\n",
    "class SOM(nn.Module):\n",
    "    \"\"\"\n",
    "    2-D Self-Organizing Map with Gaussian Neighbourhood function\n",
    "    and linearly decreasing learning rate.\n",
    "    \"\"\"\n",
    "    def __init__(self, m, n, dim, alpha=None, sigma=None):\n",
    "        super(SOM, self).__init__()\n",
    "        self.m = m\n",
    "        self.n = n\n",
    "        self.dim = dim\n",
    "        self.n_neurons = self.m * self.n\n",
    "        # gain coefficient\n",
    "        self.alpha = 0.3\n",
    "        # correction\n",
    "        self.sigma = max(m, n) / 2.0\n",
    "        \n",
    "        if alpha is not None:\n",
    "            self.alpha = float(alpha)\n",
    "        if sigma is not None:\n",
    "            self.sigma = float(sigma)\n",
    "\n",
    "        self.weights = torch.randn(self.n_neurons, dim)\n",
    "        self.locations = torch.tensor(np.array(list(self.make_grid_locations_iter(m, n))), dtype=torch.int32)\n",
    "        self.pdist = nn.PairwiseDistance(p=2)\n",
    "\n",
    "    def get_weights(self):\n",
    "        return self.weights\n",
    "\n",
    "    def get_locations(self):\n",
    "        return self.locations\n",
    "\n",
    "    def make_grid_locations_iter(self, m, n):\n",
    "        for i in range(m):\n",
    "            for j in range(n):\n",
    "                yield np.array([i, j])\n",
    "\n",
    "    def map_vects(self, input_vects):\n",
    "        to_return = []\n",
    "        for vect in input_vects:\n",
    "            min_index = min([i for i in range(self.n_neurons)],\n",
    "                            key=lambda x: np.linalg.norm(vect-self.weights[x]))\n",
    "            to_return.append(self.locations[min_index])\n",
    "\n",
    "        return to_return\n",
    "\n",
    "    def forward(self, x, learning_rate_op):\n",
    "        dists = self.pdist(x, self.weights) # compare X with every column in W. columns is a batch dimension\n",
    "        bmu_index = dists.min(0).indices # find the minimum distance\n",
    "        bmu_loc = self.locations[bmu_index,:]\n",
    "        \n",
    "        alpha_op = self.alpha * learning_rate_op\n",
    "        sigma_op = self.sigma * learning_rate_op\n",
    "\n",
    "        diff = self.locations - bmu_loc # .unsqueeze(0).repeat(self.n_neurons, 1) - don't need to copy because broadcasting will do it (ref: https://numpy.org/doc/stable/user/basics.broadcasting.html)\n",
    "        bmu_distance_squares = torch.sum(torch.pow(diff.float(), 2), 1) # array where for every neuron i: x_i ^2 + y_i ^2 -> d_i\n",
    "        neighbourhood_func = torch.exp(torch.neg(torch.div(bmu_distance_squares, sigma_op**2))) # e^{ -(d_i / sigma^2) }\n",
    "        gain_coefficient = alpha_op * neighbourhood_func\n",
    "        learning_rate_multiplier = gain_coefficient.repeat(self.dim, 1).T # copy to every dimension\n",
    "        delta = torch.mul(learning_rate_multiplier, x - self.weights) # (x - self.weights) - uses broadcasting too\n",
    "\n",
    "        self.weights += delta\n",
    "    \n",
    "    def forward_no_training(self, x):\n",
    "        # find a location where the distance between x and m_i is the minimum \n",
    "        min_index = torch.linalg.vector_norm(x - self.weights, ord=2, dim=1).min(0).indices\n",
    "        return self.locations[min_index]\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: sort colors\n",
    "\n",
    "Colors - 3-dimensional vectors. We organize them on 2D grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#Training inputs for RGBcolors\n",
    "colors = torch.tensor([\n",
    "    [0., 0., 0.],\n",
    "    [0., 0., 1.],\n",
    "    [0., 0., 0.5],\n",
    "    [0.125, 0.529, 1.0],\n",
    "    [0.33, 0.4, 0.67],\n",
    "    [0.6, 0.5, 1.0],\n",
    "    [0., 1., 0.],\n",
    "    [1., 0., 0.],\n",
    "    [0., 1., 1.],\n",
    "    [1., 0., 1.],\n",
    "    [1., 1., 0.],\n",
    "    [1., 1., 1.],\n",
    "    [.33, .33, .33],\n",
    "    [.5, .5, .5],\n",
    "    [.66, .66, .66]\n",
    "])\n",
    "color_names = [\n",
    "    'black', 'blue', 'darkblue', 'skyblue',\n",
    "    'greyblue', 'lilac', 'green', 'red',\n",
    "    'cyan', 'violet', 'yellow', 'white',\n",
    "    'darkgrey', 'mediumgrey', 'lightgrey'\n",
    "]\n",
    "\n",
    "#Train a 20x30 SOM with 100 iterations\n",
    "m = 20\n",
    "n = 30\n",
    "n_iter = 100\n",
    "som = SOM(m, n, 3)\n",
    "for iter_no in range(n_iter):\n",
    "    #Train with each vector one by one\n",
    "    for i in range(len(colors)):\n",
    "        learning_rate_op = 1.0 - iter_no/(1.0*n_iter)\n",
    "        som(colors[i], learning_rate_op)\n",
    "\n",
    "#Store a centroid grid for easy retrieval later on\n",
    "centroid_grid = [[] for i in range(m)]\n",
    "weights = som.get_weights()\n",
    "locations = som.get_locations()\n",
    "for i, loc in enumerate(locations):\n",
    "    centroid_grid[loc[0]].append(weights[i].numpy())\n",
    "\n",
    "#Get output grid\n",
    "image_grid = centroid_grid\n",
    "\n",
    "#Map colours to their closest neurons\n",
    "mapped = som.map_vects(colors)\n",
    "\n",
    "#Plot\n",
    "plt.imshow(image_grid)\n",
    "plt.title('Color SOM')\n",
    "for i, m in enumerate(mapped):\n",
    "    plt.text(m[1], m[0], color_names[i], ha='center', va='center',\n",
    "             bbox=dict(facecolor='white', alpha=0.5, lw=0))\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step by step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = som.locations - som.locations[2]\n",
    "bmu_distance_squares = torch.sum(torch.pow(diff.float(), 2), 1)\n",
    "alpha_op = som.alpha\n",
    "sigma_op = som.sigma\n",
    "neighbourhood_func = torch.exp(torch.neg(torch.div(bmu_distance_squares, sigma_op**2)))\n",
    "gain_coefficient = alpha_op * neighbourhood_func\n",
    "learning_rate_multiplier = gain_coefficient.repeat(3, 1).T # copy to every dimension\n",
    "learning_rate_multiplier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors[4] - som.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.mul(learning_rate_multiplier, colors[4] - som.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = colors[4]\n",
    "#torch.linalg.vector_norm(x - som.weights, ord=2, dim=0)\n",
    "[np.linalg.norm(x-som.weights[i]) for i in range(som.n_neurons)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.norm(x-som.weights[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.linalg.vector_norm(x - som.weights[0], ord=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.linalg.vector_norm(x - som.weights, ord=2, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.linalg.vector_norm(x - som.weights, ord=2, dim=1).min(0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Triangle experiment\n",
    "\n",
    "Let's reproduce an experiment from [Kohonen's paper](https://sci2s.ugr.es/keel/pdf/algorithm/articulo/1990-Kohonen-PIEEE.pdf). It's about random dots that become organized as a curve that evenly takes the whole space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v_x, v_y, v_z \\in [0,1]\n",
    "def vector_to_barycentric_coord(v):\n",
    "    v /= v.sum(dim=1, keepdim=True)\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate vertices of an equilateral triangle\n",
    "triangle_side = 1.0\n",
    "half_height = np.sqrt(3) / 2 * triangle_side\n",
    "triangle_points = np.array([[0, 0], \n",
    "                            [triangle_side, 0], \n",
    "                            [triangle_side / 2, half_height]])\n",
    "\n",
    "def plot_triangle_and_data(data):\n",
    "    # Plotting the equilateral triangle\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.fill(triangle_points[:, 0], triangle_points[:, 1], 'b', alpha=0.3, label=\"Equilateral Triangle\")\n",
    "\n",
    "    # Plotting the random vectors inside the triangle\n",
    "    origin = np.array([0, 0])  # origin point for vectors\n",
    "    line_segments_x = []\n",
    "    line_segments_y = []\n",
    "    for i in range(data.shape[0]):\n",
    "        vec = data[i].numpy()\n",
    "        if i < data.shape[0] - 1:\n",
    "            next_vec = data[i+1].numpy()\n",
    "            line_segments_x.append(vec[0])\n",
    "            line_segments_x.append(next_vec[0])\n",
    "            line_segments_y.append(vec[1])\n",
    "            line_segments_y.append(next_vec[1])\n",
    "        # plt.plot(vec, next_vec, color='r')\n",
    "        # bold points\n",
    "        #plt.plot(vec[0], vec[1], 'bo') \n",
    "        # vector line\n",
    "        #plt.quiver(origin[0], origin[1], vec[0], vec[1], angles='xy', scale_units='xy', scale=1, color='g', alpha=0.6)\n",
    "\n",
    "    # connection between one point and the next\n",
    "    plt.plot(line_segments_x, line_segments_y, color='r')\n",
    "\n",
    "    # Set plot limits and labels\n",
    "    plt.xlim(-0.25, 1.25)\n",
    "    plt.ylim(-0.25, 1.25)\n",
    "    #plt.gca().set_aspect('equal', adjustable='box')\n",
    "    plt.axhline(0, color='black',linewidth=0.5)\n",
    "    plt.axvline(0, color='black',linewidth=0.5)\n",
    "    #plt.legend()\n",
    "    plt.title('Equilateral Triangle and Random Vectors Inside')\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `random_barycentric_coordinates` generates 3 random weights for each point and normalizes them so that they sum to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_barycentric_coordinates(n_points):\n",
    "    barycentric_coords = torch.rand(n_points, 3)\n",
    "    barycentric_coords /= barycentric_coords.sum(dim=1, keepdim=True)\n",
    "    return barycentric_coords"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just 10 random points in a equilateral triangle. First, a 3D vector created from three uniformly distributed values in a single unit cube. Then they are converted into 2D points (blue balls) (or we can think about them as 2D vectors as depicted by a green arrows but that's all fiction hehe). This conversion uses barycentric coordinate system and thus all 3D values from [0,1] interval lay inside the triangle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Generate 10 random points inside the triangle using barycentric coordinates\n",
    "n_points = 100\n",
    "bary_coords = random_barycentric_coordinates(n_points)\n",
    "\n",
    "# bary_coords = torch.tensor([\n",
    "#     [0.5,0.5,0],\n",
    "#     [0.33,0.33,0.33],\n",
    "#     [0,0,1],\n",
    "# ], dtype=torch.float32)\n",
    "\n",
    "# Convert barycentric coordinates to 2D points inside the triangle\n",
    "vectors_in_triangle = torch.matmul(bary_coords, torch.tensor(triangle_points).float())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors_in_triangle.shape\n",
    "plot_triangle_and_data(vectors_in_triangle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bary_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n_points = 100\n",
    "\n",
    "m = 100\n",
    "n = 1\n",
    "n_iter = 5000\n",
    "som = SOM(m, n, 3)\n",
    "\n",
    "\n",
    "for iter_no in range(n_iter):\n",
    "    bary_coords = random_barycentric_coordinates(n_points)\n",
    "    data = bary_coords\n",
    "    #Train with each vector one by one\n",
    "    for i in range(len(data)):\n",
    "        learning_rate_op = 1.0 - iter_no/(1.0*n_iter)\n",
    "        som(data[i], learning_rate_op)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = som.get_weights()\n",
    "points_in_triangle = torch.matmul(w, torch.tensor(triangle_points).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_triangle_and_data(points_in_triangle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Store a centroid grid for easy retrieval later on\n",
    "weights = som.get_weights()\n",
    "locations = som.get_locations()\n",
    "\n",
    "#Get output grid\n",
    "image_grid = centroid_grid\n",
    "\n",
    "#Map colours to their closest neurons\n",
    "mapped = som.map_vects(torch.Tensor(colors))\n",
    "\n",
    "#Plot\n",
    "plt.imshow(image_grid)\n",
    "plt.title('Color SOM')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffusers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
